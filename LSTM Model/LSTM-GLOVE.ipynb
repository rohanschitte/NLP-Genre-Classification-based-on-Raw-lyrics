{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Data and Preprocessing (Same in All notebooks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('/users/rohanchitte/downloads/Dataset_lyrics.csv_lyrics.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>song</th>\n",
       "      <th>year</th>\n",
       "      <th>artist</th>\n",
       "      <th>genre</th>\n",
       "      <th>lyrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>ego-remix</td>\n",
       "      <td>2009</td>\n",
       "      <td>beyonce-knowles</td>\n",
       "      <td>Pop</td>\n",
       "      <td>Oh baby, how you doing?\\nYou know I'm gonna cu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>then-tell-me</td>\n",
       "      <td>2009</td>\n",
       "      <td>beyonce-knowles</td>\n",
       "      <td>Pop</td>\n",
       "      <td>playin' everything so easy,\\nit's like you see...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>honesty</td>\n",
       "      <td>2009</td>\n",
       "      <td>beyonce-knowles</td>\n",
       "      <td>Pop</td>\n",
       "      <td>If you search\\nFor tenderness\\nIt isn't hard t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>you-are-my-rock</td>\n",
       "      <td>2009</td>\n",
       "      <td>beyonce-knowles</td>\n",
       "      <td>Pop</td>\n",
       "      <td>Oh oh oh I, oh oh oh I\\n[Verse 1:]\\nIf I wrote...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>black-culture</td>\n",
       "      <td>2009</td>\n",
       "      <td>beyonce-knowles</td>\n",
       "      <td>Pop</td>\n",
       "      <td>Party the people, the people the party it's po...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362232</th>\n",
       "      <td>362232</td>\n",
       "      <td>who-am-i-drinking-tonight</td>\n",
       "      <td>2012</td>\n",
       "      <td>edens-edge</td>\n",
       "      <td>Country</td>\n",
       "      <td>I gotta say\\nBoy, after only just a couple of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362233</th>\n",
       "      <td>362233</td>\n",
       "      <td>liar</td>\n",
       "      <td>2012</td>\n",
       "      <td>edens-edge</td>\n",
       "      <td>Country</td>\n",
       "      <td>I helped you find her diamond ring\\nYou made m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362234</th>\n",
       "      <td>362234</td>\n",
       "      <td>last-supper</td>\n",
       "      <td>2012</td>\n",
       "      <td>edens-edge</td>\n",
       "      <td>Country</td>\n",
       "      <td>Look at the couple in the corner booth\\nLooks ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362235</th>\n",
       "      <td>362235</td>\n",
       "      <td>christ-alone-live-in-studio</td>\n",
       "      <td>2012</td>\n",
       "      <td>edens-edge</td>\n",
       "      <td>Country</td>\n",
       "      <td>When I fly off this mortal earth\\nAnd I'm meas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362236</th>\n",
       "      <td>362236</td>\n",
       "      <td>amen</td>\n",
       "      <td>2012</td>\n",
       "      <td>edens-edge</td>\n",
       "      <td>Country</td>\n",
       "      <td>I heard from a friend of a friend of a friend ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>266557 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         index                         song  year           artist    genre  \\\n",
       "0            0                    ego-remix  2009  beyonce-knowles      Pop   \n",
       "1            1                 then-tell-me  2009  beyonce-knowles      Pop   \n",
       "2            2                      honesty  2009  beyonce-knowles      Pop   \n",
       "3            3              you-are-my-rock  2009  beyonce-knowles      Pop   \n",
       "4            4                black-culture  2009  beyonce-knowles      Pop   \n",
       "...        ...                          ...   ...              ...      ...   \n",
       "362232  362232    who-am-i-drinking-tonight  2012       edens-edge  Country   \n",
       "362233  362233                         liar  2012       edens-edge  Country   \n",
       "362234  362234                  last-supper  2012       edens-edge  Country   \n",
       "362235  362235  christ-alone-live-in-studio  2012       edens-edge  Country   \n",
       "362236  362236                         amen  2012       edens-edge  Country   \n",
       "\n",
       "                                                   lyrics  \n",
       "0       Oh baby, how you doing?\\nYou know I'm gonna cu...  \n",
       "1       playin' everything so easy,\\nit's like you see...  \n",
       "2       If you search\\nFor tenderness\\nIt isn't hard t...  \n",
       "3       Oh oh oh I, oh oh oh I\\n[Verse 1:]\\nIf I wrote...  \n",
       "4       Party the people, the people the party it's po...  \n",
       "...                                                   ...  \n",
       "362232  I gotta say\\nBoy, after only just a couple of ...  \n",
       "362233  I helped you find her diamond ring\\nYou made m...  \n",
       "362234  Look at the couple in the corner booth\\nLooks ...  \n",
       "362235  When I fly off this mortal earth\\nAnd I'm meas...  \n",
       "362236  I heard from a friend of a friend of a friend ...  \n",
       "\n",
       "[266557 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered = data[data['lyrics'].notnull()]\n",
    "filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "185493\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "cleaned = filtered.copy()\n",
    "\n",
    "# Remove punctuation\n",
    "cleaned['lyrics'] = cleaned['lyrics'].str.replace(\"[-\\?.,\\/#!$%\\^&\\*;:{}=\\_~()]\", ' ')\n",
    "\n",
    "# Remove song-related identifiers like [Chorus] or [Verse]\n",
    "cleaned['lyrics'] = cleaned['lyrics'].str.replace(\"\\[(.*?)\\]\", ' ')\n",
    "cleaned['lyrics'] = cleaned['lyrics'].str.replace(\"' | '\", ' ')\n",
    "cleaned['lyrics'] = cleaned['lyrics'].str.replace('x[0-9]+', ' ')\n",
    "\n",
    "# Remove all songs without lyrics (e.g. instrumental pieces)\n",
    "cleaned = cleaned[cleaned['lyrics'].str.strip().str.lower() != 'instrumental']\n",
    "\n",
    "# Remove any songs with corrupted/non-ASCII characters, unavailable lyrics\n",
    "cleaned = cleaned[~cleaned['lyrics'].str.contains(r'[^\\x00-\\x7F]+')]\n",
    "cleaned = cleaned[cleaned['lyrics'].str.strip() != '']\n",
    "cleaned = cleaned[cleaned['genre'].str.lower() != 'not available']\n",
    "\n",
    "#Selecting Pop, Rock, Country, Jazz\n",
    "cleaned = cleaned.loc[(cleaned['genre'] == 'Pop') | \n",
    "            (cleaned['genre'] == 'Country') |\n",
    "            (cleaned['genre'] == 'Rock') |\n",
    "            (cleaned['genre'] == 'Hip-Hop') |\n",
    "            (cleaned['genre'] == 'Jazz') ]\n",
    "cleaned.reset_index(inplace = True)\n",
    "\n",
    "cleaned\n",
    "print(len(cleaned))\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('english')\n",
    "#removing stop words from lyrics\n",
    "\n",
    "cleaned['lyrics'] = cleaned['lyrics'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))\n",
    "\n",
    "#lemmatizing lyrics\n",
    "import nltk\n",
    "\n",
    "w_tokenizer = nltk.tokenize.WhitespaceTokenizer()\n",
    "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "\n",
    "def lemmatize_text(text, flg_lemm=True):\n",
    "    #Convert string to list (tokenize)\n",
    "    lst_text = text.split()\n",
    "\n",
    "    ## Lemmatisation (convert the word into root word)\n",
    "    if flg_lemm == True:\n",
    "        lem = nltk.stem.wordnet.WordNetLemmatizer()\n",
    "        lst_text = [lem.lemmatize(word) for word in lst_text]\n",
    "        \n",
    "    ## back to string from list\n",
    "    text = \" \".join(lst_text)\n",
    "    return text\n",
    "    \n",
    "#cleaned[\"lyrics\"] = cleaned[\"lyrics\"].apply(lemmatize_text)\n",
    "\n",
    "cleaned[\"lyrics\"]  = cleaned[\"lyrics\"].apply(lambda x:  lemmatize_text(x))\n",
    "\n",
    "df = cleaned.drop(labels=[\"level_0\", \"index\",\"song\",\"year\",\"artist\"], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting Data into training and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = train_test_split(df, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>genre</th>\n",
       "      <th>lyrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>35835</td>\n",
       "      <td>Jazz</td>\n",
       "      <td>I dance ask I dance ask I dance madame My hear...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2538</td>\n",
       "      <td>Hip-Hop</td>\n",
       "      <td>Sonic boom head dread cause he's tread Upon Fl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>63159</td>\n",
       "      <td>Rock</td>\n",
       "      <td>If I could turn page In time I'd rearrange Jus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6483</td>\n",
       "      <td>Rock</td>\n",
       "      <td>record stop stop skipping equipped stor ear fu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15496</td>\n",
       "      <td>Hip-Hop</td>\n",
       "      <td>Hey yeah ya know I like playersNo Diggity No d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61208</th>\n",
       "      <td>10254</td>\n",
       "      <td>Hip-Hop</td>\n",
       "      <td>We're never done found place belong Don't stan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61209</th>\n",
       "      <td>31630</td>\n",
       "      <td>Country</td>\n",
       "      <td>It's fake hoax nowhere road one go anywhere an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61210</th>\n",
       "      <td>107267</td>\n",
       "      <td>Rock</td>\n",
       "      <td>I've spent much time throwing rock window That...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61211</th>\n",
       "      <td>67806</td>\n",
       "      <td>Rock</td>\n",
       "      <td>You're lookin fine long time I still remember ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61212</th>\n",
       "      <td>23935</td>\n",
       "      <td>Pop</td>\n",
       "      <td>I I get creepin feelin' That might start belie...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>61213 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        index    genre                                             lyrics\n",
       "0       35835     Jazz  I dance ask I dance ask I dance madame My hear...\n",
       "1        2538  Hip-Hop  Sonic boom head dread cause he's tread Upon Fl...\n",
       "2       63159     Rock  If I could turn page In time I'd rearrange Jus...\n",
       "3        6483     Rock  record stop stop skipping equipped stor ear fu...\n",
       "4       15496  Hip-Hop  Hey yeah ya know I like playersNo Diggity No d...\n",
       "...       ...      ...                                                ...\n",
       "61208   10254  Hip-Hop  We're never done found place belong Don't stan...\n",
       "61209   31630  Country  It's fake hoax nowhere road one go anywhere an...\n",
       "61210  107267     Rock  I've spent much time throwing rock window That...\n",
       "61211   67806     Rock  You're lookin fine long time I still remember ...\n",
       "61212   23935      Pop  I I get creepin feelin' That might start belie...\n",
       "\n",
       "[61213 rows x 3 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.reset_index() \n",
    "df_test.reset_index() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_test split\n",
    "x_tr, y_tr = df_train['lyrics'].values, df_train['genre'].values\n",
    "x_val, y_val = df_test['lyrics'].values, df_test['genre'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function to calculcate max length of the sequence in the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_length(df_train):\n",
    "    \"\"\"\n",
    "    get max token counts from train data, \n",
    "    so we use this number as fixed length input to LSTM cell\n",
    "    \"\"\"\n",
    "    max_length = 0\n",
    "    for row in df_train['lyrics']:\n",
    "        if len(row.split(\" \")) > max_length:\n",
    "            max_length = len(row.split(\" \"))\n",
    "    return max_length\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3666"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maximumlen = get_max_length(df_train)\n",
    "maximumlen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One hot encoding genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def genre_encode(genre):\n",
    "    \"\"\"\n",
    "    return one hot encoding for Y value\n",
    "    \"\"\"\n",
    "    if genre == 'Pop':\n",
    "        return [1,0,0,0,0]\n",
    "    elif genre == 'Rock':\n",
    "        return [0,1,0,0,0]\n",
    "    elif genre == 'Country':\n",
    "        return [0,0,1,0,0]\n",
    "    elif genre == 'Hip-Hop':\n",
    "        return [0,0,0,1,0]\n",
    "    else:\n",
    "        return [0,0,0,0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "genres = df_train['genre'].tolist()\n",
    "y_tr = [genre_encode(genre) for genre in genres]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "genres = df_test['genre'].tolist()\n",
    "y_val = [genre_encode(genre) for genre in genres]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenization and Padding of the sequences to make their length same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "#Tokenize the sentences\n",
    "tokenizer = Tokenizer()\n",
    "\n",
    "#preparing vocabulary\n",
    "tokenizer.fit_on_texts(list(x_tr))\n",
    "\n",
    "#converting text into integer sequences\n",
    "x_tr_seq  = tokenizer.texts_to_sequences(x_tr) \n",
    "x_val_seq = tokenizer.texts_to_sequences(x_val)\n",
    "\n",
    "#padding to prepare sequences of same length\n",
    "x_tr_seq  = pad_sequences(x_tr_seq, maxlen=maximumlen)\n",
    "x_val_seq = pad_sequences(x_val_seq, maxlen=maximumlen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Pretrained Glove Word Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "# load the whole embedding into memory\n",
    "embeddings_index = dict()\n",
    "f = open('/users/rohanchitte/glove.6B.300d.txt')\n",
    "\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "\n",
    "f.close()\n",
    "print('Loaded %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "220815\n"
     ]
    }
   ],
   "source": [
    "size_of_vocabulary=len(tokenizer.word_index) + 1 #+1 for padding\n",
    "print(size_of_vocabulary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a weight matrix for words in training docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "embedding_matrix = np.zeros((size_of_vocabulary, 300))\n",
    "\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#deep learning library\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.callbacks import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 3666, 300)         66244500  \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 3666, 128)         219648    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 5)                 325       \n",
      "=================================================================\n",
      "Total params: 66,472,729\n",
      "Trainable params: 228,229\n",
      "Non-trainable params: 66,244,500\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model=Sequential()\n",
    "\n",
    "#embedding layer\n",
    "model.add(Embedding(size_of_vocabulary,300,weights=[embedding_matrix],input_length=maximumlen,trainable=False)) \n",
    "\n",
    "#lstm layer\n",
    "model.add(LSTM(128,return_sequences=True,dropout=0.2))\n",
    "\n",
    "#Global Maxpooling\n",
    "model.add(GlobalMaxPooling1D())\n",
    "\n",
    "#Dense Layer\n",
    "model.add(Dense(64,activation='relu')) \n",
    "model.add(Dense(5,activation='softmax')) \n",
    "\n",
    "#Add loss function, metrics, optimizer\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy',metrics=[\"accuracy\"]) \n",
    "\n",
    "#Adding callbacks\n",
    "#es = EarlyStopping(monitor='val_loss', mode='min', verbose=1,patience=3)  \n",
    "\n",
    "#mc=ModelCheckpoint('best_model.h5', monitor='val_acc', mode='max', save_best_only=True,verbose=1)  \n",
    "\n",
    "#Print summary of model\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "971/971 [==============================] - 57327s 59s/step - loss: 0.9087 - accuracy: 0.6608 - val_loss: 0.8444 - val_accuracy: 0.6809\n",
      "Epoch 2/5\n",
      "971/971 [==============================] - 54529s 56s/step - loss: 0.8149 - accuracy: 0.6924 - val_loss: 0.8185 - val_accuracy: 0.6884\n",
      "Epoch 3/5\n",
      "971/971 [==============================] - 74745s 77s/step - loss: 0.7791 - accuracy: 0.7066 - val_loss: 0.7951 - val_accuracy: 0.7013\n",
      "Epoch 4/5\n",
      "971/971 [==============================] - 60208s 62s/step - loss: 0.7513 - accuracy: 0.7172 - val_loss: 0.8008 - val_accuracy: 0.7010\n",
      "Epoch 5/5\n",
      "971/971 [==============================] - 60168s 62s/step - loss: 0.7281 - accuracy: 0.7261 - val_loss: 0.7911 - val_accuracy: 0.7045\n"
     ]
    }
   ],
   "source": [
    "history = model.fit( np.array(x_tr_seq), np.array(y_tr), batch_size=128, epochs=5, validation_data=(np.array(x_val_seq),np.array(y_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1913/1913 [==============================] - 11597s 6s/step - loss: 0.7911 - accuracy: 0.7045\n",
      "0.7045398950576782\n"
     ]
    }
   ],
   "source": [
    "_,val_acc = model.evaluate(np.array(x_val_seq),np.array(y_val))\n",
    "print(val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "# serialize weights to HDF5\n",
    "model.save_weights(\"lyrics-5-categories-model-glove.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
