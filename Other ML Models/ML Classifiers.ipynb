{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Data (Same in all notebooks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('/users/rohanchitte/downloads/Dataset_lyrics.csv_lyrics.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing (Same in all notebooks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>song</th>\n",
       "      <th>year</th>\n",
       "      <th>artist</th>\n",
       "      <th>genre</th>\n",
       "      <th>lyrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>ego-remix</td>\n",
       "      <td>2009</td>\n",
       "      <td>beyonce-knowles</td>\n",
       "      <td>Pop</td>\n",
       "      <td>Oh baby, how you doing?\\nYou know I'm gonna cu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>then-tell-me</td>\n",
       "      <td>2009</td>\n",
       "      <td>beyonce-knowles</td>\n",
       "      <td>Pop</td>\n",
       "      <td>playin' everything so easy,\\nit's like you see...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>honesty</td>\n",
       "      <td>2009</td>\n",
       "      <td>beyonce-knowles</td>\n",
       "      <td>Pop</td>\n",
       "      <td>If you search\\nFor tenderness\\nIt isn't hard t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>you-are-my-rock</td>\n",
       "      <td>2009</td>\n",
       "      <td>beyonce-knowles</td>\n",
       "      <td>Pop</td>\n",
       "      <td>Oh oh oh I, oh oh oh I\\n[Verse 1:]\\nIf I wrote...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>black-culture</td>\n",
       "      <td>2009</td>\n",
       "      <td>beyonce-knowles</td>\n",
       "      <td>Pop</td>\n",
       "      <td>Party the people, the people the party it's po...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362232</th>\n",
       "      <td>362232</td>\n",
       "      <td>who-am-i-drinking-tonight</td>\n",
       "      <td>2012</td>\n",
       "      <td>edens-edge</td>\n",
       "      <td>Country</td>\n",
       "      <td>I gotta say\\nBoy, after only just a couple of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362233</th>\n",
       "      <td>362233</td>\n",
       "      <td>liar</td>\n",
       "      <td>2012</td>\n",
       "      <td>edens-edge</td>\n",
       "      <td>Country</td>\n",
       "      <td>I helped you find her diamond ring\\nYou made m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362234</th>\n",
       "      <td>362234</td>\n",
       "      <td>last-supper</td>\n",
       "      <td>2012</td>\n",
       "      <td>edens-edge</td>\n",
       "      <td>Country</td>\n",
       "      <td>Look at the couple in the corner booth\\nLooks ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362235</th>\n",
       "      <td>362235</td>\n",
       "      <td>christ-alone-live-in-studio</td>\n",
       "      <td>2012</td>\n",
       "      <td>edens-edge</td>\n",
       "      <td>Country</td>\n",
       "      <td>When I fly off this mortal earth\\nAnd I'm meas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362236</th>\n",
       "      <td>362236</td>\n",
       "      <td>amen</td>\n",
       "      <td>2012</td>\n",
       "      <td>edens-edge</td>\n",
       "      <td>Country</td>\n",
       "      <td>I heard from a friend of a friend of a friend ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>266557 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         index                         song  year           artist    genre  \\\n",
       "0            0                    ego-remix  2009  beyonce-knowles      Pop   \n",
       "1            1                 then-tell-me  2009  beyonce-knowles      Pop   \n",
       "2            2                      honesty  2009  beyonce-knowles      Pop   \n",
       "3            3              you-are-my-rock  2009  beyonce-knowles      Pop   \n",
       "4            4                black-culture  2009  beyonce-knowles      Pop   \n",
       "...        ...                          ...   ...              ...      ...   \n",
       "362232  362232    who-am-i-drinking-tonight  2012       edens-edge  Country   \n",
       "362233  362233                         liar  2012       edens-edge  Country   \n",
       "362234  362234                  last-supper  2012       edens-edge  Country   \n",
       "362235  362235  christ-alone-live-in-studio  2012       edens-edge  Country   \n",
       "362236  362236                         amen  2012       edens-edge  Country   \n",
       "\n",
       "                                                   lyrics  \n",
       "0       Oh baby, how you doing?\\nYou know I'm gonna cu...  \n",
       "1       playin' everything so easy,\\nit's like you see...  \n",
       "2       If you search\\nFor tenderness\\nIt isn't hard t...  \n",
       "3       Oh oh oh I, oh oh oh I\\n[Verse 1:]\\nIf I wrote...  \n",
       "4       Party the people, the people the party it's po...  \n",
       "...                                                   ...  \n",
       "362232  I gotta say\\nBoy, after only just a couple of ...  \n",
       "362233  I helped you find her diamond ring\\nYou made m...  \n",
       "362234  Look at the couple in the corner booth\\nLooks ...  \n",
       "362235  When I fly off this mortal earth\\nAnd I'm meas...  \n",
       "362236  I heard from a friend of a friend of a friend ...  \n",
       "\n",
       "[266557 rows x 6 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered = data[data['lyrics'].notnull()]\n",
    "filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "185493\n"
     ]
    }
   ],
   "source": [
    "cleaned = filtered.copy()\n",
    "\n",
    "# Remove punctuation\n",
    "cleaned['lyrics'] = cleaned['lyrics'].str.replace(\"[-\\?.,\\/#!$%\\^&\\*;:{}=\\_~()]\", ' ')\n",
    "\n",
    "# Remove song-related identifiers like [Chorus] or [Verse]\n",
    "cleaned['lyrics'] = cleaned['lyrics'].str.replace(\"\\[(.*?)\\]\", ' ')\n",
    "cleaned['lyrics'] = cleaned['lyrics'].str.replace(\"' | '\", ' ')\n",
    "cleaned['lyrics'] = cleaned['lyrics'].str.replace('x[0-9]+', ' ')\n",
    "\n",
    "# Remove all songs without lyrics (e.g. instrumental pieces)\n",
    "cleaned = cleaned[cleaned['lyrics'].str.strip().str.lower() != 'instrumental']\n",
    "\n",
    "# Remove any songs with corrupted/non-ASCII characters, unavailable lyrics\n",
    "cleaned = cleaned[~cleaned['lyrics'].str.contains(r'[^\\x00-\\x7F]+')]\n",
    "cleaned = cleaned[cleaned['lyrics'].str.strip() != '']\n",
    "cleaned = cleaned[cleaned['genre'].str.lower() != 'not available']\n",
    "\n",
    "#Selecting Pop, Rock, Country, Jazz\n",
    "cleaned = cleaned.loc[(cleaned['genre'] == 'Pop') | \n",
    "            (cleaned['genre'] == 'Country') |\n",
    "            (cleaned['genre'] == 'Rock') |\n",
    "            (cleaned['genre'] == 'Hip-Hop') |\n",
    "            (cleaned['genre'] == 'Jazz') ]\n",
    "cleaned.reset_index(inplace = True)\n",
    "\n",
    "cleaned\n",
    "print(len(cleaned))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop = stopwords.words('english')\n",
    "#removing stop words from lyrics\n",
    "\n",
    "cleaned['lyrics'] = cleaned['lyrics'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lemmatizing lyrics\n",
    "import nltk\n",
    "\n",
    "w_tokenizer = nltk.tokenize.WhitespaceTokenizer()\n",
    "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "\n",
    "def lemmatize_text(text, flg_lemm=True):\n",
    "    #Convert string to list (tokenize)\n",
    "    lst_text = text.split()\n",
    "\n",
    "    ## Lemmatisation (convert the word into root word)\n",
    "    if flg_lemm == True:\n",
    "        lem = nltk.stem.wordnet.WordNetLemmatizer()\n",
    "        lst_text = [lem.lemmatize(word) for word in lst_text]\n",
    "        \n",
    "    ## back to string from list\n",
    "    text = \" \".join(lst_text)\n",
    "    return text\n",
    "    \n",
    "#cleaned[\"lyrics\"] = cleaned[\"lyrics\"].apply(lemmatize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned[\"lyrics\"]  = cleaned[\"lyrics\"].apply(lambda x:  lemmatize_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = cleaned.drop(labels=[\"level_0\", \"index\",\"song\",\"year\",\"artist\"], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting Data, One hot Encoding and Text Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>genre</th>\n",
       "      <th>lyrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>35835</td>\n",
       "      <td>Jazz</td>\n",
       "      <td>I dance ask I dance ask I dance madame My hear...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2538</td>\n",
       "      <td>Hip-Hop</td>\n",
       "      <td>Sonic boom head dread cause he's tread Upon Fl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>63159</td>\n",
       "      <td>Rock</td>\n",
       "      <td>If I could turn page In time I'd rearrange Jus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6483</td>\n",
       "      <td>Rock</td>\n",
       "      <td>record stop stop skipping equipped stor ear fu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15496</td>\n",
       "      <td>Hip-Hop</td>\n",
       "      <td>Hey yeah ya know I like playersNo Diggity No d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61208</th>\n",
       "      <td>10254</td>\n",
       "      <td>Hip-Hop</td>\n",
       "      <td>We're never done found place belong Don't stan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61209</th>\n",
       "      <td>31630</td>\n",
       "      <td>Country</td>\n",
       "      <td>It's fake hoax nowhere road one go anywhere an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61210</th>\n",
       "      <td>107267</td>\n",
       "      <td>Rock</td>\n",
       "      <td>I've spent much time throwing rock window That...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61211</th>\n",
       "      <td>67806</td>\n",
       "      <td>Rock</td>\n",
       "      <td>You're lookin fine long time I still remember ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61212</th>\n",
       "      <td>23935</td>\n",
       "      <td>Pop</td>\n",
       "      <td>I I get creepin feelin' That might start belie...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>61213 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        index    genre                                             lyrics\n",
       "0       35835     Jazz  I dance ask I dance ask I dance madame My hear...\n",
       "1        2538  Hip-Hop  Sonic boom head dread cause he's tread Upon Fl...\n",
       "2       63159     Rock  If I could turn page In time I'd rearrange Jus...\n",
       "3        6483     Rock  record stop stop skipping equipped stor ear fu...\n",
       "4       15496  Hip-Hop  Hey yeah ya know I like playersNo Diggity No d...\n",
       "...       ...      ...                                                ...\n",
       "61208   10254  Hip-Hop  We're never done found place belong Don't stan...\n",
       "61209   31630  Country  It's fake hoax nowhere road one go anywhere an...\n",
       "61210  107267     Rock  I've spent much time throwing rock window That...\n",
       "61211   67806     Rock  You're lookin fine long time I still remember ...\n",
       "61212   23935      Pop  I I get creepin feelin' That might start belie...\n",
       "\n",
       "[61213 rows x 3 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train, df_test = train_test_split(df, test_size=0.33, random_state=42)\n",
    "df_train.reset_index() \n",
    "df_test.reset_index() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_test split\n",
    "x_tr = df_train['lyrics'].values\n",
    "x_val = df_test['lyrics'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def genre_encode(genre):\n",
    "    \"\"\"\n",
    "    return one hot encoding for Y value\n",
    "    \"\"\"\n",
    "    if genre == 'Pop':\n",
    "        return 0\n",
    "    elif genre == 'Country':\n",
    "        return 1\n",
    "    elif genre == 'Rock':\n",
    "        return 2\n",
    "    elif genre == 'Hip-Hop':\n",
    "        return 3\n",
    "    else:\n",
    "        return 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "genres = df_train['genre'].tolist()\n",
    "y_tr = [genre_encode(genre) for genre in genres]\n",
    "y_tr = np.array(y_tr)\n",
    "\n",
    "genres = df_test['genre'].tolist()\n",
    "y_val = [genre_encode(genre) for genre in genres]\n",
    "y_val = np.array(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = vectorizer.fit_transform(x_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors_test = vectorizer.transform(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "204679"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(61213, 204679)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MultionomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=0.03)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "clf = MultinomialNB(alpha=.03)\n",
    "clf.fit(vectors, y_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = clf.predict(vectors_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6660023197686766"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(y_val, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model=RandomForestClassifier(n_estimators=300) \n",
    "model=model.fit(vectors,y_tr)\n",
    "pred_rf = model.predict(vectors_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 3, 2, ..., 2, 2, 2])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.691666802803326"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(y_val, pred_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils.np_utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2, 2, ..., 2, 2, 0])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_tr = to_categorical(y_tr)\n",
    "y_val = to_categorical(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0., 0.],\n",
       "       [1., 0., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors.sort_indices()\n",
    "vectors_test.sort_indices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(124280, 204679)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(61213, 204679)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#deep learning library\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.callbacks import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the model\n",
    "model1 = Sequential()\n",
    "model1.add(Dense(64, input_dim=vectors.shape[1], activation='relu'))\n",
    "model1.add(Dense(5, activation='softmax'))\n",
    "model1.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/indexed_slices.py:447: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/sequential/dense/embedding_lookup_sparse/Reshape_1:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/sequential/dense/embedding_lookup_sparse/Reshape:0\", shape=(None, 64), dtype=float32), dense_shape=Tensor(\"gradient_tape/sequential/dense/embedding_lookup_sparse/Cast:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "971/971 [==============================] - 164s 167ms/step - loss: 0.9155 - accuracy: 0.6637 - val_loss: 0.8088 - val_accuracy: 0.6948\n",
      "Epoch 2/5\n",
      "971/971 [==============================] - 162s 167ms/step - loss: 0.6927 - accuracy: 0.7373 - val_loss: 0.7941 - val_accuracy: 0.7014\n",
      "Epoch 3/5\n",
      "971/971 [==============================] - 160s 165ms/step - loss: 0.5850 - accuracy: 0.7763 - val_loss: 0.8206 - val_accuracy: 0.6983\n",
      "Epoch 4/5\n",
      "971/971 [==============================] - 163s 168ms/step - loss: 0.5047 - accuracy: 0.8085 - val_loss: 0.8611 - val_accuracy: 0.6925\n",
      "Epoch 5/5\n",
      "971/971 [==============================] - 165s 169ms/step - loss: 0.4391 - accuracy: 0.8337 - val_loss: 0.9161 - val_accuracy: 0.6853\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "# fitting the model\n",
    "m1 = model1.fit(vectors, y_tr, batch_size=batch_size, epochs=5, validation_data=(vectors_test, y_val))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
